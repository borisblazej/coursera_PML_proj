---
title: "Practical Machine Learning | Course Project"
output: html_notebook
---

# 1. Introduction

The goal of this project is to predict the manner in which barbell lifts have been done correctly and incorrectly in 5 different ways.
This is the "classe" variable in the training set. Details on the background and data can be found at [Coursera Project Instructions](https://www.coursera.org/learn/practical-machine-learning/supplement/PvInj/course-project-instructions-read-first%5D) or <http://groupware.les.inf.puc-rio.br/har>.

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = TRUE,
	warning = FALSE
)

library(tidyverse)
library(caret)
library(rattle)
```

# 2. Data

The data can be found here: [training](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) and [testing](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv). The data consists of 160 variables and \~20.000 rows (training) and 20 rows (task/validation). We clean the data and remove:

* first 5 columns as they do not help predicting
* columns without relevant content "", "#DIV/0!", ...
* columns containing NA values
* columns containing "near zero variance"


```{r data, echo=FALSE}
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")

training1 <- training %>% 
    select(-X, # unsuitable predictor
           -user_name, # unsuitable predictor
           -raw_timestamp_part_1, # unsuitable predictor
           -raw_timestamp_part_2, # unsuitable predictor
           -cvtd_timestamp, # unsuitable predictor
           -kurtosis_yaw_belt, # only "" and "#DIV/0!"
           -skewness_yaw_belt, # only "" and "#DIV/0!"
           -kurtosis_yaw_dumbbell, # only "" and "#DIV/0!"
           -skewness_yaw_dumbbell, # only "" and "#DIV/0!"
           -kurtosis_yaw_forearm, # only "" and "#DIV/0!"
           -skewness_yaw_forearm, # only "" and "#DIV/0!
           -amplitude_yaw_dumbbell, # only "" and "#DIV/0!"
           -amplitude_yaw_forearm, # only "" and "#DIV/0!"
           -amplitude_yaw_belt) # only "" and "#DIV/0!"

training1$classe <- as.factor(training1$classe)

training2 <- training1[, colSums(is.na(training1)) == 0]
    
NZV <- nearZeroVar(training2)
training3 <- training2[, -NZV]

set.seed(666) 
train_index <- createDataPartition(training3$classe, p = 0.7, list = FALSE)

training_final <- training3[train_index,]
testing_final <- training3[-train_index,]
rm(training, training1, training2, training3)


task <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

task1 <- task %>% 
    select(-X, # unsuitable predictor
           -user_name, # unsuitable predictor
           -raw_timestamp_part_1, # unsuitable predictor
           -raw_timestamp_part_2, # unsuitable predictor
           -cvtd_timestamp, # unsuitable predictor
           -kurtosis_yaw_belt, # only "" and "#DIV/0!"
           -skewness_yaw_belt, # only "" and "#DIV/0!"
           -kurtosis_yaw_dumbbell, # only "" and "#DIV/0!"
           -skewness_yaw_dumbbell, # only "" and "#DIV/0!"
           -kurtosis_yaw_forearm, # only "" and "#DIV/0!"
           -skewness_yaw_forearm, # only "" and "#DIV/0!
           -amplitude_yaw_dumbbell, # only "" and "#DIV/0!"
           -amplitude_yaw_forearm, # only "" and "#DIV/0!"
           -amplitude_yaw_belt) # only "" and "#DIV/0!"

task2 <- task1[, colSums(is.na(task1)) == 0]

NZV <- nearZeroVar(task2)
task_final <- task2[, -NZV]

rm(task, task1, task2)

table(training_final$classe)

```

The outcome is in the variable "classe" is one out of "A", "B", "C", "D", "E".

# 3. Modelling

## 3.1 Linear Model

```{r train linear}
#specify the cross-validation method
ctrl <- trainControl(method = "cv", number = 5)

fit_linear <- train(classe ~., 
             method="glm", 
             data =training_final, 
             trControl = ctrl,
             na.action = na.exclude)

predict_linear <- predict(fit_linear, testing_final)

fancyRpartPlot(fit_linear$finalModel)

cm_linar <- confusionMatrix(predict_linear, testing_final$classe)

plot(cm_linar$table, 
     col = cm_linar$byClass, 
     main = paste("Decision Tree - Accuracy =",
                  round(cm_linar$overall['Accuracy'], 
                        4)))
```


## 3.2 Decision tree
```{r train tree}
#specify the cross-validation method
ctrl <- trainControl(method = "cv", number = 5)

fit_tree <- train(classe ~., 
             method="rpart", 
             data =training_final, 
             trControl = ctrl,
             na.action = na.exclude)

predict_tree <- predict(fit_tree, testing_final)

#fancyRpartPlot(fit_tree$finalModel)

cm_tree <- confusionMatrix(predict_tree, testing_final$classe)

plot(cm_tree$table, 
     col = cm_tree$byClass, 
     main = paste("Decision Tree - Accuracy =",
                  round(cm_tree$overall['Accuracy'], 
                        4)))
```

## 3.3 Random Forrest
